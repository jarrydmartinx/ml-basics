{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-linalg-opt-work.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jarrydmartinx/ml-basics/blob/master/linear_algebra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSi3FWcLPjy0",
        "colab_type": "text"
      },
      "source": [
        "# Linear Algebra and Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOmhzp4cPjy2",
        "colab_type": "text"
      },
      "source": [
        "###### COMP4670/8600 - Introduction to Statistical Machine Learning - Tutorial 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWKkGB6hPjy3",
        "colab_type": "text"
      },
      "source": [
        "### Linear algebra\n",
        "\n",
        "Write down the definitions, being careful to specify conditions (if needed) when they exist.\n",
        "\n",
        "1. The eigenvector decomposition of a matrix $C$.\n",
        "2. The solution of a linear system of equations $Ax=b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCpE1fsEPjy5",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_B1-TsPPjy6",
        "colab_type": "text"
      },
      "source": [
        "### Dot product\n",
        "\n",
        "Recall the definition of a dot product between two vectors. Calculate the following:\n",
        "\n",
        "1. The length of a vector\n",
        "    $$x = \n",
        "    \\begin{bmatrix}\n",
        "        0.1\\\\1.2\\\\-3\n",
        "    \\end{bmatrix}\n",
        "    $$\n",
        "2. The distance between $x$ and\n",
        "    $$y =\n",
        "    \\begin{bmatrix}\n",
        "        -2\\\\0\\\\-0.3\n",
        "    \\end{bmatrix}\n",
        "    $$\n",
        "3. Are $x$ and $y$ orthogonal?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF_bXzJrPjy7",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OTxEARiPjy8",
        "colab_type": "text"
      },
      "source": [
        "### Projection\n",
        "\n",
        "For a subspace $U = \\left[\n",
        "\\begin{bmatrix}\n",
        "1\\\\1\\\\1\n",
        "\\end{bmatrix}\n",
        ",\n",
        "\\begin{bmatrix}\n",
        "0\\\\1\\\\2\n",
        "\\end{bmatrix}\n",
        "\\right]\\subset \\RR^3$ and $\\vec x = \\begin{bmatrix}\n",
        "6\\\\0\\\\0\n",
        "\\end{bmatrix}\\in\\RR^3$\n",
        "find the coordinates $\\vec\\lambda$ of $\\vec x$ in terms of the subspace $U$,\n",
        "the projection point $\\pi_U(\\vec x)$ and the projection\n",
        "matrix $\\mat P_\\pi$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvJVGxbrPjy9",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uapSuyGVPjy-",
        "colab_type": "text"
      },
      "source": [
        "## Optimisation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgCGO9lSPjy_",
        "colab_type": "text"
      },
      "source": [
        "$\\newcommand{\\trace}[1]{\\operatorname{tr}\\left\\{#1\\right\\}}$\n",
        "$\\newcommand{\\Norm}[1]{\\lVert#1\\rVert}$\n",
        "$\\newcommand{\\RR}{\\mathbb{R}}$\n",
        "$\\newcommand{\\inner}[2]{\\langle #1, #2 \\rangle}$\n",
        "$\\newcommand{\\DD}{\\mathscr{D}}$\n",
        "$\\newcommand{\\grad}[1]{\\operatorname{grad}#1}$\n",
        "$\\DeclareMathOperator*{\\argmin}{arg\\,min}$\n",
        "\n",
        "Setting up python environment ([do not use pylab](http://carreau.github.io/posts/10-No-PyLab-Thanks.ipynb.html))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uz2izP0EPjzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.optimize as opt\n",
        "import time\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBWTsAH6PjzE",
        "colab_type": "text"
      },
      "source": [
        "Consider the following cost function $ f(X) $ defined\n",
        "over the space of real $ n \\times p $ matrices\n",
        "\\begin{equation}\n",
        "  f(X) = \\frac{1}{2} \\trace{X^T C X N} + \\mu \\frac{1}{4} \\Norm{N - X^T X}^2_F\n",
        "\\end{equation}\n",
        "where $ X \\in \\RR^{n \\times p} $, $ n \\ge p $, and the matrix $ C $ is symmetric, \n",
        "such that $ C = C^T $. The scalar $ \\mu $ is assumed to be larger than the $p$th smallest \n",
        "eigenvalue of $ C $. The matrix $ N $ is diagonal with distinct positive entries\n",
        "on the diagonal.\n",
        "The trace of a square matrix $ A $ is denoted as $ \\trace{A} $, and\n",
        "the Frobenius norm of an arbitrary matrix $ A $ is defined as $ \\Norm{A}_F = \\sqrt{\\trace{A^T A}} $.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFRRnm-cPjzF",
        "colab_type": "text"
      },
      "source": [
        "## Frobenious Norm\n",
        "\n",
        "Implement a Python function ```frobenius_norm``` which accepts an arbitrary matrix $ A $ and returns\n",
        "$ \\Norm{A}_F $ using the formula given. (Use ```numpy.trace``` and ```numpy.sqrt```.)\n",
        "1. Given a matrix $ A \\in \\RR^{n \\times p} $, what is the complexity of your implementation of ```frobenius_norm```\n",
        "using the formula above?\n",
        "2. Can you come up with a faster implementation, if you were additionally told that $ p \\ge n $ ?\n",
        "3. Can you find an even faster implementation than in 1. and 2.? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu8l6VDlPjzG",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlZHOcYoPjzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def frobenius_norm(x: np.ndarray):\n",
        "    \"\"\"Computes the Frobenius norm of an nxp matrix x\n",
        "    \n",
        "        x: an nxp matrix n > p\n",
        "        \n",
        "    Returns:\n",
        "        The Frobenius norm of x\n",
        "    \"\"\"\n",
        "    \n",
        "    vec_x = x.flatten()\n",
        "    \n",
        "    return np.sqrt(np.dot(vec_x, vec_x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7b83e429-041f-49bc-9833-4e6cc53c2c11",
        "id": "sb-rFVWtX8gq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "rand_mat = np.random.rand(1000, 1000)\n",
        "\n",
        "%timeit frobenius_norm(rand_mat)\n",
        "%timeit np.linalg.norm(rand_mat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 loops, best of 3: 3.36 ms per loop\n",
            "1000 loops, best of 3: 384 Âµs per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rARn5cgPjzJ",
        "colab_type": "text"
      },
      "source": [
        "## Cost Function $f(X)$ with matrix argument\n",
        "\n",
        "Implement the cost function defined as $f(X)$ above as a function ```cost_function_for_matrix```\n",
        "in Python.\n",
        "\n",
        "Hint: As good programmers, we do not use global variables in subroutines.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m0K1V0aYcVCZ",
        "colab": {}
      },
      "source": [
        "# replace this with your solution\n",
        "\n",
        "def cost_function_for_matrix(x: np.ndarray, \n",
        "                             N: np.ndarray, \n",
        "                             C: np.ndarray,\n",
        "                             mu: float) -> float:\n",
        "    \n",
        "    \n",
        "    trace = np.trace(x.T @ C @ x @ N)\n",
        "    \n",
        "    return 0.5 * trace + mu / 4 * frobenius_norm(N - x.T @ x) ** 2\n",
        "\n",
        "\n",
        "# replace this with your solution\n",
        "\n",
        "def cost_function_for_vector(x: np.ndarray,\n",
        "                             n: int,\n",
        "                             p: int,\n",
        "                             N: np.ndarray, \n",
        "                             C: np.ndarray,\n",
        "                             mu: float) -> float:\n",
        "    \n",
        "    x.reshape(n, p)\n",
        "    \n",
        "    trace = np.trace(x.T @ C @ x @ N)\n",
        "    \n",
        "    return 0.5 * trace + mu / 4 * frobenius_norm(N - x.T @ x) ** 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZPAQumAPjzM",
        "colab_type": "text"
      },
      "source": [
        "## Cost Function $f(X)$ with vector argument\n",
        "\n",
        "Many standard optimisation routines work only with vectors. Fortunately, as vector spaces,\n",
        "the space of matrices $ \\RR^{n \\times p} $ \n",
        "and the space of vectors $ \\RR^{n p} $ are isomorphic. What does this mean?\n",
        "\n",
        "Implement the cost function $ f(X) $ given $ X $ as a vector and call it ```cost_function_for_vector```.\n",
        "Which extra arguments do you need for the cost function?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rl6SnBvbqzp",
        "colab_type": "code",
        "outputId": "a18235e8-982f-4726-8a3b-872943904114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "x = np.random.rand(2, 2)\n",
        "C = np.random.rand(2, 2)\n",
        "N = np.random.rand(2, 2)\n",
        "mu = 20\n",
        "\n",
        "print(cost_function_for_matrix(x, N, C, mu))\n",
        "\n",
        "x.flatten()\n",
        "cost_function_for_vector(x, 2, 2, N, C, mu)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11.16314893744447\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11.16314893744447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJdA9U9MPjzP",
        "colab_type": "text"
      },
      "source": [
        "## Construction of a random matrix $C$ with given eigenvalues\n",
        "\n",
        "A diagonal matrix has the nice property that the eigenvalues can be directly read off\n",
        "the diagonal. Given a diagonal matrix $ C \\in \\RR^{n \\times n} $ with distinct eigenvalues, \n",
        "how many different diagonal matrices have the same set of eigenvalues?\n",
        "\n",
        "Given a diagonal matrix $ C \\in \\RR^{n \\times n} $ with distinct eigenvalues,\n",
        "how many different matrices have the same set of eigenvalues?\n",
        "\n",
        "Given a set of $ n $ distinct real eigenvalues $ \\mathcal{E} = \\{e_1, \\dots, e_n \\} $, \n",
        "write a Python function **random_matrix_from_eigenvalues** which takes a list of\n",
        "eigenvalues $ E $ and returns a random symmetric matrix $ C $ having the same eigenvalues."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npS9620kPjzQ",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TucYNksePjzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace this with your solution\n",
        "\n",
        "def random_matrix_from_eigenvalues(eigenvalues: np.ndarray):\n",
        "    \n",
        "    print(eigenvalues)\n",
        "    rand_vec = np.random.rand(len(eigenvalues))\n",
        "    \n",
        "    rand_mat = np.outer(rand_vec, rand_vec)\n",
        "    \n",
        "    print(rand_mat.shape)\n",
        "    \n",
        "    print((rand_mat @ np.diag(eigenvalues) @ rand_mat.T).shape)\n",
        "    \n",
        "    return rand_mat @ np.diag(eigenvalues) @ rand_mat.T\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEFSO6qNiRTF",
        "colab_type": "code",
        "outputId": "e30d8285-3af8-48d0-edd1-18ba938d7e69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "random_mat = random_matrix_from_eigenvalues(np.random.rand(2))\n",
        "\n",
        "np.linalg.eigvals(random_mat)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.97567659 0.31793377]\n",
            "(2, 2)\n",
            "(2, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.38777878e-17, 1.06067450e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcJetx0FPjzY",
        "colab_type": "text"
      },
      "source": [
        "## Minimising the cost function $f(X)$\n",
        "\n",
        "Use the minimisation functions ```fmin``` or ```fmin_powell``` provided in the\n",
        "Python package ```scipy.optimize``` to minimise the cost function ```cost_function_for_vector```.\n",
        "\n",
        "Hint: Use the argument ```args``` in the minimisation functions  ```fmin``` or ```fmin_powell``` \n",
        "to provide the extra parameters to\n",
        "your cost function ```cost_function_for_vector```.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_J3DkPuPjzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace this with your solution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfMKNt3DPjzb",
        "colab_type": "text"
      },
      "source": [
        "## Gradient of $f(X)$\n",
        "\n",
        "Calculate the gradient for the cost function $f(X)$ given the\n",
        "inner product on the space of real matrices $ n \\times p $ is defined as\n",
        "\\begin{equation}\n",
        "  \\inner{A}{B} = \\trace{A^T B}\n",
        "\\end{equation}\n",
        "\n",
        "Implement a function ```gradient_for_vector``` which takes $ X $ as a vector, and\n",
        "returns the gradient of $ f(X) $ as a vector.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSvZQfwuPjzb",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF3fIbFiPjzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace this with your solution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QEe3GS2Pjze",
        "colab_type": "text"
      },
      "source": [
        "## Minimising the cost function $f(X)$ using the gradient\n",
        "\n",
        "Use the minimisation functions ```fmin_cg``` or ```fmin_bfgs``` provided in the\n",
        "Python package ```scipy.optimize``` to minimise the cost function ```cost_function_for_vector``` utilising the gradient ```gradient_for_vector```.\n",
        "\n",
        "Compare the speed of convergence to the minimisation with ```fmin``` or ```fmin_powell```.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-IO3YJbPjzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace this with your solution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHBnYH2tPjzh",
        "colab_type": "text"
      },
      "source": [
        "## Minima of $f(X)$\n",
        "\n",
        "Compare the columns $x_1,\\dots, x_p$ of the matrix $X^\\star$ which minimises $ f(X) $ \n",
        "\\begin{equation}\n",
        "  X^\\star = \\argmin_{X \\in \\RR^{n \\times p}} f(X)\n",
        "\\end{equation}\n",
        "\n",
        "with the eigenvectors related to the smallest eigenvalues of $ C $.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPAf7u6gPjzi",
        "colab_type": "text"
      },
      "source": [
        "### <span style=\"color:blue\">Answer</span>\n",
        "<i>--- replace this with your solution ---</i>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5JyXlVoOPjzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# replace this with your solution"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8uQpyeOPjzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}